{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2834f285",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "<span><h1 style=\"font-family:verdana;\"><center><img src=\"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" alt=\"Scikit-Learn\" width=200>Scikit-learn</center></h1></span>\n",
    "<p><center style=\"color:#159364; font-family:cursive;\">Scikit-learn is a popular machine learning library that provides tools for data pre-processing, including feature extraction, scaling, and normalization<br><br>1. Simple and efficient tools for predictive data analysis<br>2. Accessible to everybody, and reusable in various contexts<br> 3. Built on NumPy, SciPy, and matplotlib<br> 4. Open source, commercially usable - BSD license</center></p>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820932a",
   "metadata": {},
   "source": [
    "<h2><center>Installation of Scikit-learn</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da9ea8",
   "metadata": {},
   "source": [
    "<h3>Requirements:</h3>\n",
    "<p>1. You need to install Python and Pip in your system</p>\n",
    "<p>2. Open your cmd and run <code>pip install scikit-learn</code></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11adb3c3",
   "metadata": {},
   "source": [
    "<h2><center>Importing Scikit-learn</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100ca515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Example dataset with missing values and categorical data\n",
    "X = np.array([[1, 2, 3, 'A'], [4, np.nan, 6, 'B'], [7, 8, 9, 'C']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793b5b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '2', '3', 'A'],\n",
       "       ['4', 'nan', '6', 'B'],\n",
       "       ['7', '8', '9', 'C']], dtype='<U11')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22af6727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data:\n",
      " [[-1.22474487 -1.         -1.22474487]\n",
      " [ 0.                 nan  0.        ]\n",
      " [ 1.22474487  1.          1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X[:, :3])\n",
    "print(\"Scaled data:\\n\", X_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1730f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed data:\n",
      " [[1. 2.]\n",
      " [4. 5.]\n",
      " [7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# Handling missing data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X[:, :2])\n",
    "print(\"Imputed data:\\n\", X_imputed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d489708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data:\n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X[:, 3].reshape(-1, 1))\n",
    "print(\"Encoded data:\\n\", X_encoded.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7124332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data:\n",
      " [[0.  0.  0. ]\n",
      " [0.5 nan 0.5]\n",
      " [1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# Data normalization\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_normalized = minmax_scaler.fit_transform(X[:, :3])\n",
    "print(\"Normalized data:\\n\", X_normalized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f7f28",
   "metadata": {},
   "source": [
    "<p>In this example, the <code>X</code> array represents a simple dataset with missing values and categorical data. The code then demonstrates how to perform feature scaling, handling missing data, encoding categorical data, data normalization, and dimensionality reduction using Scikit-learn functions.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
